{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# COMP 588 Final Project Experiment\n",
        "\n",
        "Author: Zhongjie Wu\n",
        "\n",
        "Acknowledgments: Special thanks to the YaleNLP Lab and Yilun Zhao for their guidance on this project.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNWXPWnpdW7q",
        "outputId": "9cd929e0-7688-4e22-d266-c3d3a455472d"
      },
      "outputs": [],
      "source": [
        "def read_jsonl_file(path):\n",
        "  data = []\n",
        "  with open(path, 'r') as f:\n",
        "    for line in f:\n",
        "      data.append(json.loads(line))\n",
        "  return data\n",
        "\n",
        "def read_json(filename):\n",
        "  with open(filename, 'r') as f:\n",
        "    data = json.load(f)\n",
        "  return data\n",
        "\n",
        "\n",
        "path_jsonl = 'questions.jsonl'\n",
        "qas = read_jsonl_file(path_jsonl)\n",
        "\n",
        "path_json = 'papers.json'\n",
        "paper_dict = read_json(path_json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def search_and_store_img(path, qa_num=None):\n",
        "    # Extract the required part of the path\n",
        "    path_components = path.split(\"/\")\n",
        "    extracted_path = \"../\" + \"/\".join(path_components[-2:])\n",
        "\n",
        "    # Check if qa_num is provided and not None\n",
        "    if qa_num is not None:\n",
        "        # Create a new directory name\n",
        "        dir_name = f\"q_{qa_num}\"\n",
        "\n",
        "        # Create the directory if it does not exist\n",
        "        if not os.path.exists(dir_name):\n",
        "            os.makedirs(dir_name)\n",
        "\n",
        "        # Copy the file to the new directory\n",
        "        destination_path = os.path.join(dir_name, os.path.basename(path))\n",
        "        shutil.copy(extracted_path, destination_path)\n",
        "\n",
        "def get_related_info(paper_dict, qa, qa_num=None):\n",
        "    q = qa['question']\n",
        "    a = qa['answer']\n",
        "    anchor_id = qa['anchor_arxiv_id']\n",
        "    ref_id = qa['reference_arxiv_id']\n",
        "    anchor_info = qa['source_anchor']\n",
        "    ref_info = qa['source_reference']\n",
        "    \n",
        "    is_text_anchor = False if anchor_info[0] == '/' else True\n",
        "    is_text_ref = False if ref_info[0] == '/' else True\n",
        "\n",
        "    result = \"Question: \" + q + \"\\n\" + \"Text Context: \\n\"\n",
        "    anchor_found = None\n",
        "    ref_found = None\n",
        "    if is_text_anchor:\n",
        "        for section in paper_dict[anchor_id]['full_text']:\n",
        "            if section['section_name'] ==  anchor_info:\n",
        "                anchor_found = section['paragraphs']\n",
        "                result += anchor_found\n",
        "\n",
        "        if anchor_info == 'Abstract_1':\n",
        "            anchor_found = paper_dict[anchor_id]['abstract']\n",
        "            result += anchor_found\n",
        "\n",
        "    if is_text_ref:\n",
        "        for section in paper_dict[ref_id]['full_text']:\n",
        "            if section['section_name'] ==  ref_info:\n",
        "                ref_found = section['paragraphs']\n",
        "                result += ref_found\n",
        "        \n",
        "        if ref_info == 'Abstract_1':\n",
        "            ref_found = paper_dict[ref_id]['abstract']\n",
        "            result += ref_found\n",
        "\n",
        "    if anchor_found == None and qa_num is not None and not is_text_anchor:\n",
        "        # print(f\"extract QA pair - {qa_num} anchor image context... \")\n",
        "        search_and_store_img(anchor_info, qa_num)\n",
        "        # print(\"done!\")\n",
        "\n",
        "\n",
        "    if ref_found == None and qa_num is not None and not is_text_ref:\n",
        "        # print(f\"extract QA pair - {qa_num} ref image context... \")\n",
        "        search_and_store_img(ref_info, qa_num)\n",
        "        # print(\"done!\")\n",
        "\n",
        "    if not ref_found and not anchor_found and qa_num:\n",
        "        print(f\"Error in QA pair {qa_num}\")\n",
        "\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {},
      "outputs": [],
      "source": [
        "full_context = []\n",
        "full_context_with_prompt = []\n",
        "\n",
        "prompt = \"Answer the following question using both the given text and image context. Remember to limit your response within 50 words and do not use any knowledge not given in the context.\"\n",
        "\n",
        "for i in range(len(qas)):\n",
        "    context = get_related_info(paper_dict, qas[i], i)\n",
        "    full_context.append(context)\n",
        "    full_context_with_prompt.append(prompt + '\\n' + context)\n",
        "    # print(f\"QA pair {i} extraction complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {},
      "outputs": [],
      "source": [
        "def read_first_image(folder_path):\n",
        "    # Iterate over files in the specified folder\n",
        "    for file in os.listdir(folder_path):\n",
        "        # Assuming the image files are in JPG, JPEG, or PNG format\n",
        "        if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            image_path = os.path.join(folder_path, file)\n",
        "\n",
        "            # Read and return the image data\n",
        "            with open(image_path, 'rb') as img_file:\n",
        "                return img_file.read()\n",
        "\n",
        "    # Return None if no image file is found\n",
        "    return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Multi-modal BARD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {},
      "outputs": [],
      "source": [
        "from bardapi import Bard\n",
        "from bardapi import BardCookies\n",
        "import os\n",
        "\n",
        "# Replace with your own cookie id.\n",
        "cookie_dict = {\n",
        "    \"__Secure-1PSID\": \"##########################\",\n",
        "    \"__Secure-1PSIDTS\": \"##########################\"\n",
        "}\n",
        "\n",
        "bard = BardCookies(cookie_dict=cookie_dict)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {},
      "outputs": [],
      "source": [
        "def query(question, qid, bard):\n",
        "    path = f\"./q_{qid}\"\n",
        "    image_data = read_first_image(path)\n",
        "    answer = bard.ask_about_image(question, image_data)['content']\n",
        "    return answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bard_answers = []\n",
        "for i in range(len(full_context_with_prompt)):\n",
        "    if len(full_context_with_prompt[i]) > 4096:\n",
        "        truncate = full_context_with_prompt[i][:4096]\n",
        "        answer = query(truncate, i, bard)\n",
        "    else:\n",
        "        answer = query(full_context_with_prompt[i], i, bard)\n",
        "    pair = {\n",
        "        'id': i,\n",
        "        'prompt': full_context_with_prompt[i],\n",
        "        'image_folder': i,\n",
        "        'answer': answer  \n",
        "    }\n",
        "    bard_answers.append(pair)\n",
        "    print(f\"Bard answered QA pair {i+1} successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"bard_answer.jsonl\", \"w\") as file:\n",
        "    # Iterate over each item in the list\n",
        "    for item in bard_answers:\n",
        "        # Convert the item to a JSON string\n",
        "        json_string = json.dumps(item)\n",
        "        # Write the JSON string to the file with a newline\n",
        "        file.write(json_string + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "execution_count": 173,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Calculate how many examples are truncated due to bard token limit\n",
        "l = [len(i) for i in full_context_with_prompt]\n",
        "count = 0\n",
        "for i in l:\n",
        "    if i <= 4096:\n",
        "        count += 1\n",
        "count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(len(full_context_with_prompt)):\n",
        "    if l[i] <= 4096:\n",
        "        bard_answers[i]['truncated'] = False\n",
        "    else:\n",
        "        bard_answers[i]['truncated'] = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"bard_answers_with_bertscore.jsonl\", \"w\") as file:\n",
        "    # Iterate over each item in the list\n",
        "    for item in bard_answers:\n",
        "        # Convert the item to a JSON string\n",
        "        json_string = json.dumps(item)\n",
        "        # Write the JSON string to the file with a newline\n",
        "        file.write(json_string + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Multimodal-Bard BERTScore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 309.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.35 seconds, 2.89 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 263.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.38 seconds, 2.63 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:01<00:00,  1.11s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 215.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 1.13 seconds, 0.89 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 269.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.94 seconds, 1.06 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 304.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.29 seconds, 3.42 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 241.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.39 seconds, 2.60 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 268.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.85 seconds, 1.17 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 345.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.57 seconds, 1.77 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 247.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.34 seconds, 2.97 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:01<00:00,  1.44s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 214.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 1.45 seconds, 0.69 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 230.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.50 seconds, 2.00 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 234.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.38 seconds, 2.60 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:02<00:00,  2.04s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 130.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 2.06 seconds, 0.48 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 319.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.45 seconds, 2.21 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 307.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.41 seconds, 2.44 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  4.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 345.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.25 seconds, 4.04 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 309.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.77 seconds, 1.31 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  4.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 166.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.26 seconds, 3.89 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 282.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.49 seconds, 2.03 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 347.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.87 seconds, 1.15 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 367.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.31 seconds, 3.24 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 314.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.54 seconds, 1.85 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 358.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.36 seconds, 2.81 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 376.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.28 seconds, 3.55 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 368.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.97 seconds, 1.04 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 265.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.39 seconds, 2.56 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 318.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.68 seconds, 1.47 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 295.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.55 seconds, 1.83 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 381.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.43 seconds, 2.31 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 274.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.86 seconds, 1.16 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 320.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.56 seconds, 1.79 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 270.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.35 seconds, 2.82 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 368.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.54 seconds, 1.85 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:01<00:00,  1.20s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 378.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 1.21 seconds, 0.83 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 260.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.61 seconds, 1.64 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 346.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.67 seconds, 1.48 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 333.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.41 seconds, 2.47 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 294.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.39 seconds, 2.57 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 323.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.35 seconds, 2.89 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 371.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.33 seconds, 3.04 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 264.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.43 seconds, 2.33 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 129.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.80 seconds, 1.25 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 359.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.60 seconds, 1.66 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 312.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.90 seconds, 1.11 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 227.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.56 seconds, 1.79 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from bert_score import score\n",
        "\n",
        "for i in range(len(qas)):\n",
        "    reference = [qas[i]['answer']]\n",
        "    candidate = [bard_answers[i]['answer']]\n",
        "\n",
        "    P, R, F1 = score(candidate, reference, lang=\"en\", verbose=True)\n",
        "    bertscores = [P.item(), R.item(), F1.item()]\n",
        "    bard_answers[i]['bert_scores'] = bertscores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Multimodal-Bard ROUGE Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {},
      "outputs": [],
      "source": [
        "from rouge import Rouge\n",
        "\n",
        "rouge = Rouge()\n",
        "# i = 0\n",
        "for i in range(len(qas)):\n",
        "    reference = [qas[i]['answer']]\n",
        "    hypothesis = [bard_answers[i]['answer']]\n",
        "\n",
        "    scores = rouge.get_scores(hypothesis, reference)\n",
        "    bard_answers[i]['rouge_scores'] = scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'rouge-1': {'r': 0.5294117647058824,\n",
              "   'p': 0.09782608695652174,\n",
              "   'f': 0.1651376120461241},\n",
              "  'rouge-2': {'r': 0.16666666666666666,\n",
              "   'p': 0.02040816326530612,\n",
              "   'f': 0.03636363441983481},\n",
              "  'rouge-l': {'r': 0.47058823529411764,\n",
              "   'p': 0.08695652173913043,\n",
              "   'f': 0.14678898819291306}}]"
            ]
          },
          "execution_count": 198,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bard_answers[2]['rouge_scores']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"bard_answers_bert_rouge.jsonl\", \"w\") as file:\n",
        "    # Iterate over each item in the list\n",
        "    for item in bard_answers:\n",
        "        # Convert the item to a JSON string\n",
        "        json_string = json.dumps(item)\n",
        "        # Write the JSON string to the file with a newline\n",
        "        file.write(json_string + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## GPT4v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {},
      "outputs": [],
      "source": [
        "import openai\n",
        "import base64\n",
        "import requests\n",
        "\n",
        "openai.api_base = \"https://api.keya.pw/v1\"\n",
        "# Replace with your gpt api_key.\n",
        "api_key = \"###############\"\n",
        "\n",
        "def encode_image(image_path):\n",
        "  with open(image_path, \"rb\") as image_file:\n",
        "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
        "            \n",
        "def encode_first_image(folder_path):\n",
        "    # Iterate over files in the specified folder\n",
        "    for file in os.listdir(folder_path):\n",
        "        # Assuming the image files are in JPG, JPEG, or PNG format\n",
        "        if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            image_path = os.path.join(folder_path, file)\n",
        "\n",
        "            # Read and return the encoded image data\n",
        "            with open(image_path, \"rb\") as image_file:\n",
        "                return base64.b64encode(image_file.read()).decode('utf-8')\n",
        "    # Return None if no image file is found\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "metadata": {},
      "outputs": [],
      "source": [
        "def query_4v(prompt, qid):\n",
        "    path = f\"./q_{qid}\"\n",
        "    image_data = encode_first_image(path)\n",
        "\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {api_key}\"\n",
        "    }\n",
        "\n",
        "    payload = {\n",
        "        \"model\": \"gpt-4-vision-preview\",\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\n",
        "                        \"type\": \"text\",\n",
        "                        \"text\": prompt\n",
        "                    },\n",
        "                    {\n",
        "                        \"type\": \"image_url\",\n",
        "                        \"image_url\": {\n",
        "                            \"url\": f\"data:image/png;base64,{image_data}\"\n",
        "                        }\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "        ],\n",
        "        \"max_tokens\": 50\n",
        "    }\n",
        "\n",
        "    response = requests.post(\"https://api.keya.pw/v1/chat/completions\", headers=headers, json=payload)\n",
        "    result_json = response.json()\n",
        "    \n",
        "    return result_json['choices'][0]['message']['content']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gpt4v_answers = []\n",
        "for i in range(len(full_context_with_prompt)):\n",
        "    answer = query_4v(full_context_with_prompt[i], i)\n",
        "    pair = {\n",
        "        'id': i,\n",
        "        'prompt': full_context_with_prompt[i],\n",
        "        'image_folder': i,\n",
        "        'answer': answer  \n",
        "    }\n",
        "    gpt4v_answers.append(pair)\n",
        "    print(f\"GPT4v answered QA pair {i+1} successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': 44,\n",
              " 'prompt': 'Answer the following question using both the given text and image context. Remember to limit your response within 50 words and do not use any knowledge not given in the context.\\nQuestion: For the method represented by a line with lower perplexity than Sinusoidal with L=2048 across all measured training times in the Validation Perplexity Through Training graph, what are the test perplexity results achieved by this method on the Billion Word benchmark and the WikiText-103 benchmark compared to previously published work?\\nText Context: \\n Language modeling is a basic task in natural language processing, with many applications such as speech recognition \\\\citep{arisoy:2012:wfnlm} and statistical machine translation \\\\citep{schwenk:2012:wfnlm,vaswani:2013:emnlp,baltescu2014pragmatic}. Recently, much progress has been made by neural methods \\\\citep{bengio:2003:jmlr,mikolov:2010:interspeech} based on LSTMs \\\\citep{jozefowicz2016lm}, gated convolutional networks \\\\citep{dauphin2017convlm} and self-attentional networks \\\\citep{alrfou2018chartrans}.  There are different choices for the basic unit we wish to model, including full words \\\\citep{bengio:2003:jmlr}, characters for the input \\\\citep{kim2016character}, or also the output \\\\citep{merity2018lm} as well as sub-words \\\\citep{buckman2018taacl,mielke2018spell}. Word-based models are particularly challenging since computing probabilities for all 800K words of the \\\\gbw{} benchmark is still a substantial part of the overall computation \\\\citep{chen2016strategies}.  A popular approach to lower the computational burden is to structure the output vocabulary so that not all probabilities need to be computed. The hierarchical softmax does this by introducing latent variables or clusters to simplify normalization \\\\citep{goodman:2001:icassp,morin:2005:aistats,mikolov:2011:icassp}. This has been further improved by the \\\\emph{adaptive softmax} which introduces a variable capacity scheme for output word embeddings, assigning more parameters to frequent words and fewer parameters to rare words \\\\citep{grave2017icml}.  In this paper, we introduce \\\\emph{adaptive input embeddings} which extend the adaptive softmax to input word representations. This factorization assigns more capacity to frequent words and reduces the capacity for less frequent words with the benefit of reducing overfitting to rare words. For a competitive setup on the \\\\gbw{} benchmark, adaptive input embeddings reduce the number of parameters in the input and output layers by 23\\\\% while achieving higher accuracy over fixed size embeddings. When the adaptive input representations are tied with an adaptive softmax in the output, then the number of parameters is reduced by a total of 61\\\\%.  Our experiments compare models based on word inputs, character inputs, as well as sub-word units using a self-attention architecture \\\\citep{vaswani2017transformer}. We show that models with adaptive word representations can outperform very strong character-based models while training more than twice as fast. We also substantially improve adaptive softmax by introducing additional dropout regularization in the tail projection. On the \\\\wiki{} benchmark we achieve a perplexity of 18.7, a reduction of 10.5 perplexity over the previously best published result. On the larger \\\\gbw{} benchmark our best model with adaptive input embeddings achieves 23.02 perplexity, a reduction of nearly 5 perplexity over the next best previously published result.  ',\n",
              " 'image_folder': 44,\n",
              " 'answer': 'The method represented by the line with lower perplexity than Sinusoidal with L=2048 achieves a perplexity of 18.7 on WikiText-103, reducing 10.5 perplexity over previous work, and 23.02'}"
            ]
          },
          "execution_count": 236,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gpt4v_answers[44]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"gpt4v_answer.jsonl\", \"w\") as file:\n",
        "    # Iterate over each item in the list\n",
        "    for item in gpt4v_answers:\n",
        "        # Convert the item to a JSON string\n",
        "        json_string = json.dumps(item)\n",
        "        # Write the JSON string to the file with a newline\n",
        "        file.write(json_string + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from bert_score import score\n",
        "\n",
        "for i in range(len(qas)):\n",
        "    reference = [qas[i]['answer']]\n",
        "    candidate = [gpt4v_answers[i]['answer']]\n",
        "\n",
        "    P, R, F1 = score(candidate, reference, lang=\"en\", verbose=True)\n",
        "    bertscores = [P.item(), R.item(), F1.item()]\n",
        "    gpt4v_answers[i]['bert_scores'] = bertscores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "metadata": {},
      "outputs": [],
      "source": [
        "from rouge import Rouge\n",
        "\n",
        "rouge = Rouge()\n",
        "# i = 0\n",
        "for i in range(len(qas)):\n",
        "    reference = [qas[i]['answer']]\n",
        "    hypothesis = [gpt4v_answers[i]['answer']]\n",
        "\n",
        "    scores = rouge.get_scores(hypothesis, reference)\n",
        "    gpt4v_answers[i]['rouge_scores'] = scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"gpt4v_answers_bert_rouge.jsonl\", \"w\") as file:\n",
        "    # Iterate over each item in the list\n",
        "    for item in gpt4v_answers:\n",
        "        # Convert the item to a JSON string\n",
        "        json_string = json.dumps(item)\n",
        "        # Write the JSON string to the file with a newline\n",
        "        file.write(json_string + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 247,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For QA pair 0:\n",
            "MMBard - BERTScore: P:0.8914120197296143, R:0.9374126195907593, F1:0.9138337969779968\n",
            "GPT4v - BERTScore: P:0.8705054521560669, R:0.8865202069282532, F1:0.8784397840499878\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 1:\n",
            "MMBard - BERTScore: P:0.8289973735809326, R:0.9412931203842163, F1:0.881583571434021\n",
            "GPT4v - BERTScore: P:0.8312262296676636, R:0.938875675201416, F1:0.8817775845527649\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 2:\n",
            "MMBard - BERTScore: P:0.8085586428642273, R:0.8702982068061829, F1:0.838293194770813\n",
            "GPT4v - BERTScore: P:0.8828139901161194, R:0.8905731439590454, F1:0.886676549911499\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 3:\n",
            "MMBard - BERTScore: P:0.816047728061676, R:0.8842343688011169, F1:0.8487738370895386\n",
            "GPT4v - BERTScore: P:0.8930950164794922, R:0.9521903395652771, F1:0.9216963648796082\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 4:\n",
            "MMBard - BERTScore: P:0.9192080497741699, R:0.9338749647140503, F1:0.9264834523200989\n",
            "GPT4v - BERTScore: P:0.9243866205215454, R:0.9522697925567627, F1:0.9381210803985596\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 5:\n",
            "MMBard - BERTScore: P:0.8356997966766357, R:0.8637580275535583, F1:0.8494972586631775\n",
            "GPT4v - BERTScore: P:0.8551393747329712, R:0.8704385757446289, F1:0.8627212047576904\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 6:\n",
            "MMBard - BERTScore: P:0.7931750416755676, R:0.9115542769432068, F1:0.8482544422149658\n",
            "GPT4v - BERTScore: P:0.8727861046791077, R:0.9453027248382568, F1:0.9075982570648193\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 7:\n",
            "MMBard - BERTScore: P:0.8056282997131348, R:0.8547981977462769, F1:0.8294851779937744\n",
            "GPT4v - BERTScore: P:0.8993363380432129, R:0.9068504571914673, F1:0.9030777812004089\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 8:\n",
            "MMBard - BERTScore: P:0.8575482368469238, R:0.8953791856765747, F1:0.8760554790496826\n",
            "GPT4v - BERTScore: P:0.8694990873336792, R:0.9020521640777588, F1:0.8854765295982361\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 9:\n",
            "MMBard - BERTScore: P:0.8225932121276855, R:0.903936505317688, F1:0.8613486886024475\n",
            "GPT4v - BERTScore: P:0.9168229103088379, R:0.9439867734909058, F1:0.9302065372467041\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 10:\n",
            "MMBard - BERTScore: P:0.8378718495368958, R:0.8797272443771362, F1:0.8582895398139954\n",
            "GPT4v - BERTScore: P:0.8677980899810791, R:0.8823273777961731, F1:0.8750025033950806\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 11:\n",
            "MMBard - BERTScore: P:0.863539457321167, R:0.9253475069999695, F1:0.8933756947517395\n",
            "GPT4v - BERTScore: P:0.8607304096221924, R:0.9547143578529358, F1:0.9052896499633789\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 12:\n",
            "MMBard - BERTScore: P:0.7660659551620483, R:0.8553637266159058, F1:0.8082558512687683\n",
            "GPT4v - BERTScore: P:0.906868577003479, R:0.9159733057022095, F1:0.9113982319831848\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 13:\n",
            "MMBard - BERTScore: P:0.8387664556503296, R:0.8860148191452026, F1:0.8617435097694397\n",
            "GPT4v - BERTScore: P:0.8788130879402161, R:0.9326117038726807, F1:0.9049134850502014\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 14:\n",
            "MMBard - BERTScore: P:0.8843352794647217, R:0.9327986240386963, F1:0.9079206585884094\n",
            "GPT4v - BERTScore: P:0.9271032810211182, R:0.9377384185791016, F1:0.9323905110359192\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 15:\n",
            "MMBard - BERTScore: P:0.830368161201477, R:0.8611484169960022, F1:0.8454782366752625\n",
            "GPT4v - BERTScore: P:0.9478360414505005, R:0.8568758368492126, F1:0.900063693523407\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 16:\n",
            "MMBard - BERTScore: P:0.8432832956314087, R:0.8919060230255127, F1:0.866913378238678\n",
            "GPT4v - BERTScore: P:0.9414834380149841, R:0.9289301633834839, F1:0.9351646900177002\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 17:\n",
            "MMBard - BERTScore: P:0.8762841820716858, R:0.8544761538505554, F1:0.8652427792549133\n",
            "GPT4v - BERTScore: P:0.8858296871185303, R:0.9303117990493774, F1:0.9075260162353516\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 18:\n",
            "MMBard - BERTScore: P:0.862017035484314, R:0.8348395824432373, F1:0.8482106328010559\n",
            "GPT4v - BERTScore: P:0.885847806930542, R:0.8934030532836914, F1:0.8896093964576721\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 19:\n",
            "MMBard - BERTScore: P:0.8156891465187073, R:0.8679951429367065, F1:0.8410295844078064\n",
            "GPT4v - BERTScore: P:0.8773776292800903, R:0.9152162671089172, F1:0.8958975672721863\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 20:\n",
            "MMBard - BERTScore: P:0.8486228585243225, R:0.8737403750419617, F1:0.8609984517097473\n",
            "GPT4v - BERTScore: P:0.8817996382713318, R:0.8943207263946533, F1:0.8880160450935364\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 21:\n",
            "MMBard - BERTScore: P:0.8397223949432373, R:0.8917517066001892, F1:0.8649553060531616\n",
            "GPT4v - BERTScore: P:0.8704696893692017, R:0.9048672914505005, F1:0.8873352408409119\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 22:\n",
            "MMBard - BERTScore: P:0.8322400450706482, R:0.8658342361450195, F1:0.8487048149108887\n",
            "GPT4v - BERTScore: P:0.9646963477134705, R:0.9440078735351562, F1:0.9542399644851685\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 23:\n",
            "MMBard - BERTScore: P:0.8832654356956482, R:0.8346574306488037, F1:0.8582736849784851\n",
            "GPT4v - BERTScore: P:0.8946371674537659, R:0.9028244018554688, F1:0.898712158203125\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 24:\n",
            "MMBard - BERTScore: P:0.810488224029541, R:0.8620744943618774, F1:0.8354858160018921\n",
            "GPT4v - BERTScore: P:0.8242119550704956, R:0.863703727722168, F1:0.8434959053993225\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 25:\n",
            "MMBard - BERTScore: P:0.8444375991821289, R:0.9005317091941833, F1:0.8715830445289612\n",
            "GPT4v - BERTScore: P:0.9444047212600708, R:0.893616795539856, F1:0.9183090329170227\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 26:\n",
            "MMBard - BERTScore: P:0.8299533724784851, R:0.8838342428207397, F1:0.8560467958450317\n",
            "GPT4v - BERTScore: P:0.8514618873596191, R:0.9056174159049988, F1:0.8777050971984863\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 27:\n",
            "MMBard - BERTScore: P:0.8135921955108643, R:0.8433485627174377, F1:0.8282032012939453\n",
            "GPT4v - BERTScore: P:0.8464615345001221, R:0.9242788553237915, F1:0.8836603164672852\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 28:\n",
            "MMBard - BERTScore: P:0.8492357134819031, R:0.8290977478027344, F1:0.8390458822250366\n",
            "GPT4v - BERTScore: P:0.8881241083145142, R:0.8970735669136047, F1:0.8925763368606567\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 29:\n",
            "MMBard - BERTScore: P:0.8120278120040894, R:0.8708024621009827, F1:0.8403887152671814\n",
            "GPT4v - BERTScore: P:0.8510082364082336, R:0.8761951327323914, F1:0.8634180426597595\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 30:\n",
            "MMBard - BERTScore: P:0.8544462323188782, R:0.9582129120826721, F1:0.9033595323562622\n",
            "GPT4v - BERTScore: P:0.8989579677581787, R:0.9481026530265808, F1:0.9228765368461609\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 31:\n",
            "MMBard - BERTScore: P:0.8847908973693848, R:0.8918943405151367, F1:0.8883284330368042\n",
            "GPT4v - BERTScore: P:0.8547671437263489, R:0.8662177324295044, F1:0.8604543209075928\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 32:\n",
            "MMBard - BERTScore: P:0.8529770374298096, R:0.921612560749054, F1:0.885967493057251\n",
            "GPT4v - BERTScore: P:0.8918179869651794, R:0.9191100597381592, F1:0.9052583575248718\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 33:\n",
            "MMBard - BERTScore: P:0.8500829935073853, R:0.9180989861488342, F1:0.8827828168869019\n",
            "GPT4v - BERTScore: P:0.8960198163986206, R:0.9533830881118774, F1:0.9238117933273315\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 34:\n",
            "MMBard - BERTScore: P:0.8589907288551331, R:0.9180469512939453, F1:0.8875375986099243\n",
            "GPT4v - BERTScore: P:0.8714727759361267, R:0.8869373798370361, F1:0.8791370391845703\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 35:\n",
            "MMBard - BERTScore: P:0.8561275601387024, R:0.9563323855400085, F1:0.9034599661827087\n",
            "GPT4v - BERTScore: P:0.9001418948173523, R:0.9237350225448608, F1:0.911785900592804\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 36:\n",
            "MMBard - BERTScore: P:0.8468040823936462, R:0.8620359301567078, F1:0.8543521165847778\n",
            "GPT4v - BERTScore: P:0.8535354733467102, R:0.8483479619026184, F1:0.850933849811554\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 37:\n",
            "MMBard - BERTScore: P:0.8741508722305298, R:0.9300430417060852, F1:0.9012311697006226\n",
            "GPT4v - BERTScore: P:0.9196169972419739, R:0.9255223870277405, F1:0.9225602746009827\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 38:\n",
            "MMBard - BERTScore: P:0.8790659308433533, R:0.9246000051498413, F1:0.9012582302093506\n",
            "GPT4v - BERTScore: P:0.8865788578987122, R:0.9514840841293335, F1:0.917885422706604\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 39:\n",
            "MMBard - BERTScore: P:0.9274137616157532, R:0.932458221912384, F1:0.9299291372299194\n",
            "GPT4v - BERTScore: P:0.9284290075302124, R:0.9359068274497986, F1:0.9321529865264893\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 40:\n",
            "MMBard - BERTScore: P:0.8716796636581421, R:0.963042676448822, F1:0.9150864481925964\n",
            "GPT4v - BERTScore: P:0.8845328092575073, R:0.9491811394691467, F1:0.9157173037528992\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 41:\n",
            "MMBard - BERTScore: P:0.8202619552612305, R:0.8551895022392273, F1:0.8373616933822632\n",
            "GPT4v - BERTScore: P:0.8432753682136536, R:0.8512483835220337, F1:0.847243070602417\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 42:\n",
            "MMBard - BERTScore: P:0.8412178754806519, R:0.9117621183395386, F1:0.8750705718994141\n",
            "GPT4v - BERTScore: P:0.8401454091072083, R:0.8687905073165894, F1:0.8542279005050659\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 43:\n",
            "MMBard - BERTScore: P:0.8377031683921814, R:0.9049323201179504, F1:0.8700209259986877\n",
            "GPT4v - BERTScore: P:0.9095377922058105, R:0.9588516354560852, F1:0.9335439801216125\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 44:\n",
            "MMBard - BERTScore: P:0.8788276314735413, R:0.9186884164810181, F1:0.8983160257339478\n",
            "GPT4v - BERTScore: P:0.8857436180114746, R:0.8949385285377502, F1:0.8903173804283142\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "GPT4v wins 39/45\n",
            "MMBard wins 6/45\n"
          ]
        }
      ],
      "source": [
        "gpt4v_score_bertf1 = 0\n",
        "mbard_score_bertf1 = 0\n",
        "for i in range(len(qas)):\n",
        "    print(f\"For QA pair {i}:\")\n",
        "    print(f\"MMBard - BERTScore: P:{bard_answers[i]['bert_scores'][0]}, R:{bard_answers[i]['bert_scores'][1]}, F1:{bard_answers[i]['bert_scores'][2]}\")\n",
        "    print(f\"GPT4v - BERTScore: P:{gpt4v_answers[i]['bert_scores'][0]}, R:{gpt4v_answers[i]['bert_scores'][1]}, F1:{gpt4v_answers[i]['bert_scores'][2]}\")\n",
        "    if bard_answers[i]['bert_scores'][2] > gpt4v_answers[i]['bert_scores'][2]:\n",
        "        mbard_score_bertf1 += 1\n",
        "    else:\n",
        "        gpt4v_score_bertf1 += 1\n",
        "    print(\"-*\"*40)\n",
        "\n",
        "print(f\"GPT4v wins {gpt4v_score_bertf1}/45\")\n",
        "print(f\"MMBard wins {mbard_score_bertf1}/45\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For QA pair 0:\n",
            "MMBard - F1: R-1:0.4745762667049699, R-2:0.29999999567222224, R-L:0.4067796565354784\n",
            "GPT4v - F1: R-1:0.31111110617283955, R-2:0.18604650669551123, R-L:0.2666666617283951\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 1:\n",
            "MMBard - F1: R-1:0.28070175172668516, R-2:0.16666666435555558, R-L:0.28070175172668516\n",
            "GPT4v - F1: R-1:0.42105262796398896, R-2:0.22222221876543213, R-L:0.3684210490166206\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 2:\n",
            "MMBard - F1: R-1:0.1651376120461241, R-2:0.03636363441983481, R-L:0.14678898819291306\n",
            "GPT4v - F1: R-1:0.3999999951125, R-2:0.09090908607438043, R-L:0.29999999511250003\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 3:\n",
            "MMBard - F1: R-1:0.08080807867768601, R-2:0.0, R-L:0.08080807867768601\n",
            "GPT4v - F1: R-1:0.41025640599605523, R-2:0.15789473272853197, R-L:0.358974354714004\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 4:\n",
            "MMBard - F1: R-1:0.5217391255860114, R-2:0.23529411269511738, R-L:0.43478260384688094\n",
            "GPT4v - F1: R-1:0.5106382930556813, R-2:0.33962263659665365, R-L:0.46808510156631966\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 5:\n",
            "MMBard - F1: R-1:0.15624999570312512, R-2:0.029411760679066295, R-L:0.12499999570312517\n",
            "GPT4v - F1: R-1:0.1904761854875285, R-2:0.04878048283164834, R-L:0.14285713786848087\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 6:\n",
            "MMBard - F1: R-1:0.16438355948207922, R-2:0.043010751115735976, R-L:0.1369862992081066\n",
            "GPT4v - F1: R-1:0.5714285670663266, R-2:0.2758620649702735, R-L:0.49999999563775516\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 7:\n",
            "MMBard - F1: R-1:0.13186812882985155, R-2:0.017699112365886532, R-L:0.10989010685182957\n",
            "GPT4v - F1: R-1:0.43243242746530314, R-2:0.24999999505000006, R-L:0.37837837341124914\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 8:\n",
            "MMBard - F1: R-1:0.17543859316712837, R-2:0.0, R-L:0.14035087386888281\n",
            "GPT4v - F1: R-1:0.21052631146814413, R-2:0.05263157483379533, R-L:0.10526315357340738\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 9:\n",
            "MMBard - F1: R-1:0.3010752655659614, R-2:0.10687022611269748, R-L:0.2795698892218754\n",
            "GPT4v - F1: R-1:0.533333328454321, R-2:0.35294117151864673, R-L:0.533333328454321\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 10:\n",
            "MMBard - F1: R-1:0.26666666275555556, R-2:0.04878048424449759, R-L:0.18666666275555563\n",
            "GPT4v - F1: R-1:0.2857142807256236, R-2:0.1463414584414041, R-L:0.2857142807256236\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 11:\n",
            "MMBard - F1: R-1:0.29411764316609, R-2:0.1111111076543211, R-L:0.29411764316609\n",
            "GPT4v - F1: R-1:0.5925925881481482, R-2:0.5599999956480001, R-L:0.5925925881481482\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 12:\n",
            "MMBard - F1: R-1:0.09937888009876164, R-2:0.025862067534185573, R-L:0.08695651985031445\n",
            "GPT4v - F1: R-1:0.44444443945987655, R-2:0.10810810311176064, R-L:0.3333333283487655\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 13:\n",
            "MMBard - F1: R-1:0.10909090567933895, R-2:0.0, R-L:0.10909090567933895\n",
            "GPT4v - F1: R-1:0.2926829226888757, R-2:0.09302325200649016, R-L:0.2439024348839977\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 14:\n",
            "MMBard - F1: R-1:0.4210526271345029, R-2:0.3235294072880623, R-L:0.4210526271345029\n",
            "GPT4v - F1: R-1:0.571428566473923, R-2:0.25531914393843375, R-L:0.5238095188548754\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 15:\n",
            "MMBard - F1: R-1:0.23255813572742023, R-2:0.08333333003472235, R-L:0.18604650782044357\n",
            "GPT4v - F1: R-1:0.4705882307266437, R-2:0.13333332888888905, R-L:0.4705882307266437\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 16:\n",
            "MMBard - F1: R-1:0.18367346665556022, R-2:0.06349206139455789, R-L:0.18367346665556022\n",
            "GPT4v - F1: R-1:0.5806451562955255, R-2:0.41379309845422124, R-L:0.5806451562955255\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 17:\n",
            "MMBard - F1: R-1:0.07999999520000028, R-2:0.0, R-L:0.07999999520000028\n",
            "GPT4v - F1: R-1:0.511627902433748, R-2:0.31818181368801657, R-L:0.4186046466197945\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 18:\n",
            "MMBard - F1: R-1:0.30985915045427503, R-2:0.02325580964575526, R-L:0.25352112228526097\n",
            "GPT4v - F1: R-1:0.2807017495106187, R-2:0.06666666171666703, R-L:0.24561403021237313\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 19:\n",
            "MMBard - F1: R-1:0.1553398028164766, R-2:0.014388486544175228, R-L:0.1359223270883213\n",
            "GPT4v - F1: R-1:0.46153845690088763, R-2:0.3103448228775268, R-L:0.42307691843934914\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 20:\n",
            "MMBard - F1: R-1:0.1851851819410151, R-2:0.0, R-L:0.1851851819410151\n",
            "GPT4v - F1: R-1:0.3428571385469388, R-2:0.12121211698806258, R-L:0.28571428140408167\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 21:\n",
            "MMBard - F1: R-1:0.2622950780972857, R-2:0.10666666346666677, R-L:0.2622950780972857\n",
            "GPT4v - F1: R-1:0.36363635900826446, R-2:0.09523809064625872, R-L:0.2727272680991736\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 22:\n",
            "MMBard - F1: R-1:0.19354838342872013, R-2:0.0, R-L:0.1290322543964621\n",
            "GPT4v - F1: R-1:0.7333333283333333, R-2:0.5517241329369797, R-L:0.6666666616666668\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 23:\n",
            "MMBard - F1: R-1:0.35087718810710994, R-2:0.0322580595993764, R-L:0.24561403021237313\n",
            "GPT4v - F1: R-1:0.2909090859900827, R-2:0.06896551226516089, R-L:0.2545454496264464\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 24:\n",
            "MMBard - F1: R-1:0.15126050151825438, R-2:0.012048190471767022, R-L:0.10084033345102754\n",
            "GPT4v - F1: R-1:0.17543859204678372, R-2:0.0, R-L:0.10526315345029258\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 25:\n",
            "MMBard - F1: R-1:0.26415094010679957, R-2:0.12499999736328131, R-L:0.26415094010679957\n",
            "GPT4v - F1: R-1:0.5714285664399092, R-2:0.42105262659279785, R-L:0.5714285664399092\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 26:\n",
            "MMBard - F1: R-1:0.22580644778355885, R-2:0.05333333013333353, R-L:0.22580644778355885\n",
            "GPT4v - F1: R-1:0.3499999952000001, R-2:0.09756097096966114, R-L:0.29999999520000004\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 27:\n",
            "MMBard - F1: R-1:0.0588235259731836, R-2:0.0, R-L:0.029411761267301443\n",
            "GPT4v - F1: R-1:0.533333328888889, R-2:0.3265306079966681, R-L:0.4888888844444445\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 28:\n",
            "MMBard - F1: R-1:0.2823529371238755, R-2:0.03669724397946339, R-L:0.21176470182975787\n",
            "GPT4v - F1: R-1:0.2909090859900827, R-2:0.06666666171666703, R-L:0.2545454496264464\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 29:\n",
            "MMBard - F1: R-1:0.13999999692200008, R-2:0.014492750943079679, R-L:0.0999999969220001\n",
            "GPT4v - F1: R-1:0.2857142812308674, R-2:0.0, R-L:0.214285709802296\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 30:\n",
            "MMBard - F1: R-1:0.4175824140321217, R-2:0.30088495250998515, R-L:0.4175824140321217\n",
            "GPT4v - F1: R-1:0.5614035041181903, R-2:0.4242424197015611, R-L:0.5614035041181903\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 31:\n",
            "MMBard - F1: R-1:0.4999999950617285, R-2:0.30588234802491354, R-L:0.4444444395061729\n",
            "GPT4v - F1: R-1:0.34285713789387756, R-2:0.15384614885930323, R-L:0.34285713789387756\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 32:\n",
            "MMBard - F1: R-1:0.4285714239143991, R-2:0.23423422978978986, R-L:0.38095237629535156\n",
            "GPT4v - F1: R-1:0.5217391254862423, R-2:0.2962962913336382, R-L:0.46376811099348875\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 33:\n",
            "MMBard - F1: R-1:0.39999999656799995, R-2:0.2595419817399918, R-L:0.3799999965680001\n",
            "GPT4v - F1: R-1:0.5862068918430441, R-2:0.5312499953125001, R-L:0.5862068918430441\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 34:\n",
            "MMBard - F1: R-1:0.49462365162215294, R-2:0.18181817769256206, R-L:0.38709676990172276\n",
            "GPT4v - F1: R-1:0.41269840772990685, R-2:0.14285713789387772, R-L:0.3492063442378433\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 35:\n",
            "MMBard - F1: R-1:0.3689320355886512, R-2:0.265624997052002, R-L:0.3689320355886512\n",
            "GPT4v - F1: R-1:0.5098039167243368, R-2:0.33962263659665365, R-L:0.5098039167243368\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 36:\n",
            "MMBard - F1: R-1:0.38356163891161577, R-2:0.16867469385397024, R-L:0.3013698580896979\n",
            "GPT4v - F1: R-1:0.309859149978179, R-2:0.12820512321827762, R-L:0.309859149978179\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 37:\n",
            "MMBard - F1: R-1:0.5194805146702648, R-2:0.2718446555905364, R-L:0.4935064886962389\n",
            "GPT4v - F1: R-1:0.6153846103952664, R-2:0.37499999502812503, R-L:0.5846153796260355\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 38:\n",
            "MMBard - F1: R-1:0.5079365033912825, R-2:0.28571428142351163, R-L:0.444444439899219\n",
            "GPT4v - F1: R-1:0.5925925877640604, R-2:0.3448275813555292, R-L:0.5555555507270235\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 39:\n",
            "MMBard - F1: R-1:0.508474571272623, R-2:0.23529411266435996, R-L:0.508474571272623\n",
            "GPT4v - F1: R-1:0.6071428521492348, R-2:0.3548387046826223, R-L:0.6071428521492348\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 40:\n",
            "MMBard - F1: R-1:0.5479452013811222, R-2:0.45783132129481796, R-L:0.5479452013811222\n",
            "GPT4v - F1: R-1:0.5714285667410715, R-2:0.3225806404942768, R-L:0.5714285667410715\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 41:\n",
            "MMBard - F1: R-1:0.2321428530612246, R-2:0.10738254660240544, R-L:0.1964285673469389\n",
            "GPT4v - F1: R-1:0.26470587737024226, R-2:0.1095890360968289, R-L:0.23529411266435996\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 42:\n",
            "MMBard - F1: R-1:0.33962263737095055, R-2:0.19580419196831148, R-L:0.3207547128426486\n",
            "GPT4v - F1: R-1:0.33333332833888896, R-2:0.02857142358775597, R-L:0.2666666616722223\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 43:\n",
            "MMBard - F1: R-1:0.33684210170415513, R-2:0.18978101900793867, R-L:0.31578947012520775\n",
            "GPT4v - F1: R-1:0.5882352892118416, R-2:0.5517241330796672, R-L:0.5882352892118416\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "For QA pair 44:\n",
            "MMBard - F1: R-1:0.48717948250821835, R-2:0.1682242948729148, R-L:0.41025640558514137\n",
            "GPT4v - F1: R-1:0.35087718798399514, R-2:0.09677418855359028, R-L:0.31578946868574953\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "GPT4v wins 108/135\n",
            "MMBard wins 27/135\n"
          ]
        }
      ],
      "source": [
        "gpt4v_score_rouge = 0\n",
        "mbard_score_rouge = 0\n",
        "for i in range(len(qas)):\n",
        "    print(f\"For QA pair {i}:\")\n",
        "    print(f\"MMBard - F1: R-1:{bard_answers[i]['rouge_scores'][0]['rouge-1']['f']}, R-2:{bard_answers[i]['rouge_scores'][0]['rouge-2']['f']}, R-L:{bard_answers[i]['rouge_scores'][0]['rouge-l']['f']}\")\n",
        "    print(f\"GPT4v - F1: R-1:{gpt4v_answers[i]['rouge_scores'][0]['rouge-1']['f']}, R-2:{gpt4v_answers[i]['rouge_scores'][0]['rouge-2']['f']}, R-L:{gpt4v_answers[i]['rouge_scores'][0]['rouge-l']['f']}\")\n",
        "    for type in ['rouge-1', 'rouge-2', 'rouge-l']:\n",
        "        if bard_answers[i]['rouge_scores'][0][type]['f'] > gpt4v_answers[i]['rouge_scores'][0][type]['f']:\n",
        "            mbard_score_rouge += 1\n",
        "        else:\n",
        "            gpt4v_score_rouge += 1\n",
        "    print(\"-*\"*40)\n",
        "\n",
        "print(f\"GPT4v wins {gpt4v_score_rouge}/135\")\n",
        "print(f\"MMBard wins {mbard_score_rouge}/135\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 269,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_average_scores(data, include_truncation=True, token_size_index=None, truncate_condition=4096):\n",
        "    # Initialize accumulators for each score\n",
        "    total_bert_precision, total_bert_recall, total_bert_f1 = 0, 0, 0\n",
        "    total_rouge_1_f, total_rouge_2_f, total_rouge_l_f = 0, 0, 0\n",
        "    count = 0\n",
        "\n",
        "    for i, item in enumerate(data):\n",
        "        if not include_truncation and (token_size_index[i]>truncate_condition):\n",
        "            continue\n",
        "        # Accumulate BERT scores\n",
        "        total_bert_precision += item['bert_scores'][0]\n",
        "        total_bert_recall += item['bert_scores'][1]\n",
        "        total_bert_f1 += item['bert_scores'][2]\n",
        "\n",
        "        # Accumulate ROUGE scores\n",
        "        total_rouge_1_f += item['rouge_scores'][0]['rouge-1']['f']\n",
        "        total_rouge_2_f += item['rouge_scores'][0]['rouge-2']['f']\n",
        "        total_rouge_l_f += item['rouge_scores'][0]['rouge-l']['f']\n",
        "\n",
        "        count += 1\n",
        "\n",
        "    # Calculate averages\n",
        "    avg_bert_precision = total_bert_precision / count\n",
        "    avg_bert_recall = total_bert_recall / count\n",
        "    avg_bert_f1 = total_bert_f1 / count\n",
        "    avg_rouge_1_f = total_rouge_1_f / count\n",
        "    avg_rouge_2_f = total_rouge_2_f / count\n",
        "    avg_rouge_l_f = total_rouge_l_f / count\n",
        "\n",
        "    return {\n",
        "        \"average_bert_precision\": avg_bert_precision,\n",
        "        \"average_bert_recall\": avg_bert_recall,\n",
        "        \"average_bert_f1\": avg_bert_f1,\n",
        "        \"average_rouge_1_f\": avg_rouge_1_f,\n",
        "        \"average_rouge_2_f\": avg_rouge_2_f,\n",
        "        \"average_rouge_l_f\": avg_rouge_l_f\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 275,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Multimodal-Bard (all datapoints):{'average_bert_precision': 0.8465603391329447, 'average_bert_recall': 0.8935284455617268, 'average_bert_f1': 0.8690625919236077, 'average_rouge_1_f': 0.2931313522052871, 'average_rouge_2_f': 0.1252911789289194, 'average_rouge_l_f': 0.2611285443246064}\n",
            "Multimodal-Bard (exclude truncated datapoints):{'average_bert_precision': 0.8581861654917399, 'average_bert_recall': 0.9099420557419459, 'average_bert_f1': 0.8831019798914591, 'average_rouge_1_f': 0.3651664114435156, 'average_rouge_2_f': 0.18760686989924547, 'average_rouge_l_f': 0.3341256398095118}\n",
            "GPT4v (all datapoints):{'average_bert_precision': 0.8861588305897183, 'average_bert_recall': 0.9116761181089613, 'average_bert_f1': 0.898409370581309, 'average_rouge_1_f': 0.4353121719335574, 'average_rouge_2_f': 0.22958218499428318, 'average_rouge_l_f': 0.39559463647476456}\n",
            "GPT4v (exclude truncated datapoints):{'average_bert_precision': 0.8936805551250776, 'average_bert_recall': 0.9144758308927218, 'average_bert_f1': 0.9036291415492693, 'average_rouge_1_f': 0.46175034156578615, 'average_rouge_2_f': 0.2553023349952713, 'average_rouge_l_f': 0.4337054961618357}\n"
          ]
        }
      ],
      "source": [
        "bard_result_all = calculate_average_scores(bard_answers, True)\n",
        "print(f\"Multimodal-Bard (all datapoints):{bard_result_all}\")\n",
        "\n",
        "bard_result_ex_trunc = calculate_average_scores(bard_answers, False, l)\n",
        "print(f\"Multimodal-Bard (exclude truncated datapoints):{bard_result_ex_trunc}\")\n",
        "\n",
        "gpt4v_result_all = calculate_average_scores(gpt4v_answers, True)\n",
        "print(f\"GPT4v (all datapoints):{gpt4v_result_all}\")\n",
        "\n",
        "gpt4v_result_ex_trunc = calculate_average_scores(gpt4v_answers, False, l)\n",
        "print(f\"GPT4v (exclude truncated datapoints):{gpt4v_result_ex_trunc}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
